## 对 AI Safety / AI open source 以及 large scale AI deployment 的看法
Q: 大家觉得， 人类接下来五年能实现的 super intelligence 到底能有多强，以及它到底是有多大程度的 safety concern?

研究员1：保守估计从去年这个时候到现在一年时间已经intelligence提升是2倍，那么2的5次方就是32倍

研究员2：我觉得safety是一种幻觉，当AI智力突破临界值后，是不存在可靠的手段产生“safety”的

研究员3：AI 对于人类的影线也不一定是完全的，可能是局部的，比如说，如果模型在某些特定疾病上 halluscinate 但在其他疾病上极为精准，那么人类可能会因为模型在其他疾病上都很精准所以对模型有足够的信任，但是刚好就是有那一种病的人遭殃；然后，AI 对人类的影响也不一定是在时间维度是上局部的，它也可能是代际的。比如说，如果 2010 年生下来这一代人精神上只想跟 character 谈恋爱，肉体上过几年各种娃娃也给你造得很真；然后再来个 Sam 给你发 UBI，国内发低保，那可能他们这一代人就比我们这一代更不想繁衍了。刘慈欣在一次 talk 上也讲了这个观点；再然后，当 AI 的能力到了一定程度之后，它就有自我进化的可能；我之前做 GPT bargaining 的时候 https://arxiv.org/abs/2305.10142 讨论的就是在什么样的条件下 AI 可以自我演化，后面我在 OpenAI 给 talk 的时候他们对这个问题也是关注得很深，讨论了很多，因为如果 AI 可以自我演化那就没人类什么事了。

研究员4：OAI 做过演化的研究 https://openai.com/research/evolution-through-large-models。


## 论文分享
### 1.《Transformer升级之路：15、Key归一化助力长度外推》https://kexue.fm/archives/9859 

本文介绍了笔者意外发现的一种长度外推方案“KeyNorm”——对Attention的Key序列进行L2归一化，在训练长度上取得了更好的效果，并在长度外推方面表现出显著的提升。它属于“事前修改”方案，跟其他事前修改方案如ALIBI、KERPLE等相比，它没有Local约束，因此更有希望能够Scale Up；相比于NTK-RoPE、YaRN等“事后修改”方案，它在外推的时候则不会损失训练长度内的性能。 https://mp.weixin.qq.com/s/qSJCNCH433EbF7Khr0FYrg

## 简短问答&讨论&杂谈
Q: 想问下大家现在transformer在设计hiddensize, number heads, 其他超参的时候除了考虑infrastructure还有没有别的考虑?

A: 还有位置嵌入的超参吧，比如考虑上下文调整rope的参数

Q: 请问大家一个技术问题。我用 trl.SFTTrainer finetune Vicuna，用相同的数据相同的参数 finetune，发现设置了：torch.manual_seed(42) random.seed(42) 之后，这个 finetune 得到的 ckpt evaluate 仍旧不稳定。我每次重新用相同的 dataset 去 finetune，差距非常大。该如何确保自己的 finetune 稳定呢？

A: 如果gpu上有randomness的操作可能要一个 torch.cuda.manual_seed(42).

Q: 有没有什么比较好的文章研究模型的 memorization ，背数据到底能背多厉害? 感觉现在 scale up 的性能提升蛮多就是因为模型背答案

A: (1) https://arxiv.org/abs/2310.16789  Detecting Pretraining Data from Large Language Models & https://arxiv.org/abs/2202.07646 (2) http://arxiv.org/abs/2311.04850 这篇也不错

Q: 怀疑phi model有pretrain on benchmark-like data的嫌疑

A: 感觉deepseek 1B instruct比phi的结果还离谱很多

A1: deepseek肯定没有刻意pretrain on benchmark-like data的嫌疑，但至于是否存在一些test集合天然分布在train里面，没有刻意处理（比如有一些GitHub上有一些leetcode的题解等），我们觉得这其实也是一部分知识，不应该因为潜在的benchmark包含就排除在pretrain data之外。真正要做的应该是用更新的泛化更好的benchmark测，比如用leetcode的定期新出的周赛题

A2: 谢谢解答！可能我没表达好，我“离谱”指的是我在自己的一些example里试过deepseek coder然后确实效果很好所以会很好奇2B instruction data的insight 因为-instruct version对比base model的提升再各个benchmark上也很明显

Q: 有同好记得有哪篇论文讲pua ＬＬＭ取得好效果的不?

A: https://arxiv.org/pdf/2307.11760.pdf & https://arxiv.org/pdf/2311.07590.pdf


 

